{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import apimoex\n",
    "\n",
    "from data_loader import index_history\n",
    "from data_loader import ticker_prices, get_ticker_history\n",
    "from pypfopt import expected_returns, risk_models, EfficientFrontier, objective_functions\n",
    "from optimizer import optimizer_for_tickers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ETLN', 'FIXP', 'QIWI', 'OKEY', 'OZON', 'AGRO']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\sofya\\Desktop\\Export_ru_securities-list_20250405.csv\",\n",
    "    encoding='utf-8',  # кодировка Windows, часто используется в России\n",
    "    sep=';',            # разделитель — точка с запятой\n",
    "    on_bad_lines='skip' # игнорируем строки с ошибками\n",
    ")\n",
    "df_stocks = df[df['SUPERTYPE'] == 'Депозитарные расписки']\n",
    "tickers = df_stocks['TRADE_CODE']\n",
    "tickers_list = tickers.tolist()\n",
    "tickers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: CBOM (2461 rows)\n",
      "Saved: ALRS (3144 rows)\n",
      "Saved: VTBR (3040 rows)\n",
      "Saved: MDMG (1085 rows)\n",
      "Saved: GEMC (899 rows)\n",
      "Saved: VKCO (803 rows)\n",
      "Saved: LENT (820 rows)\n",
      "Saved: RUAL (2520 rows)\n",
      "Saved: T (1344 rows)\n",
      "Saved: HEAD (141 rows)\n",
      "Saved: CNRU (2 rows)\n",
      "Saved: ENPG (1288 rows)\n",
      "Saved: YDEX (187 rows)\n",
      "Saved: BSPB (2723 rows)\n",
      "Saved: AQUA (2360 rows)\n",
      "Saved: AFKS (2725 rows)\n",
      "Saved: AFLT (4297 rows)\n",
      "Saved: VSEH (193 rows)\n",
      "Saved: GAZP (2725 rows)\n",
      "Saved: GMKN (3042 rows)\n",
      "Saved: RAGR (35 rows)\n",
      "Saved: LSRG (3550 rows)\n",
      "Saved: POSI (824 rows)\n",
      "Saved: RENI (860 rows)\n",
      "Saved: EUTR (353 rows)\n",
      "Saved: IRAO (3386 rows)\n",
      "Saved: X5 (69 rows)\n",
      "Saved: LEAS (268 rows)\n",
      "Saved: MVID (2719 rows)\n",
      "Saved: MBNK (241 rows)\n",
      "Saved: MAGN (2725 rows)\n",
      "Saved: MTLR (4032 rows)\n",
      "Saved: MTLRP (3440 rows)\n",
      "Saved: MTSS (3625 rows)\n",
      "Saved: MOEX (3020 rows)\n",
      "Saved: LKOH (5415 rows)\n",
      "Saved: BELU (1883 rows)\n",
      "Saved: NLMK (2725 rows)\n",
      "Saved: PIKK (3418 rows)\n",
      "Saved: PLZL (2722 rows)\n",
      "Saved: RTKM (5375 rows)\n",
      "Saved: RTKMP (5369 rows)\n",
      "Saved: SBER (4443 rows)\n",
      "Saved: SBERP (4443 rows)\n",
      "Saved: CHMF (2725 rows)\n",
      "Saved: SELG (2857 rows)\n",
      "Saved: SVCB (339 rows)\n",
      "Saved: FLOT (1129 rows)\n",
      "Saved: TGKA (3943 rows)\n",
      "Saved: TRNFP (2838 rows)\n",
      "Saved: HYDR (4166 rows)\n",
      "Saved: FEES (2711 rows)\n",
      "Saved: PHOR (3044 rows)\n",
      "Saved: ELFV (519 rows)\n",
      "Saved: SFIN (1821 rows)\n",
      "Saved: UPRO (2207 rows)\n",
      "Saved: ASTR (384 rows)\n",
      "Saved: SGZH (989 rows)\n",
      "Saved: RNFT (2099 rows)\n",
      "Saved: MSNG (5389 rows)\n",
      "Saved: SMLT (1113 rows)\n",
      "Saved: NVTK (3891 rows)\n",
      "Saved: ROSN (2725 rows)\n",
      "Saved: TATN (5818 rows)\n",
      "Saved: TATNP (5819 rows)\n",
      "Saved: PRMD (188 rows)\n",
      "Saved: HNFG (363 rows)\n",
      "Saved: AKRN (2716 rows)\n",
      "Saved: APTK (2716 rows)\n",
      "Saved: ABIO (2701 rows)\n",
      "Saved: WUSH (591 rows)\n",
      "Saved: OGKB (3603 rows)\n",
      "Saved: DATA (131 rows)\n",
      "Saved: FESH (2716 rows)\n",
      "Saved: DIAS (292 rows)\n",
      "Saved: IVAT (215 rows)\n",
      "Saved: KMAZ (2719 rows)\n",
      "Saved: DELI (296 rows)\n",
      "Saved: OZPH (119 rows)\n",
      "Saved: RASP (2719 rows)\n",
      "Saved: MRKV (2716 rows)\n",
      "Saved: MSRS (4042 rows)\n",
      "Saved: MRKZ (2715 rows)\n",
      "Saved: MRKS (2650 rows)\n",
      "Saved: MRKU (2710 rows)\n",
      "Saved: MRKP (3244 rows)\n",
      "Saved: MRKC (3121 rows)\n",
      "Saved: SVAV (2719 rows)\n",
      "Saved: SOFL (394 rows)\n",
      "Saved: SNGS (2725 rows)\n",
      "Saved: SNGSP (2725 rows)\n",
      "Saved: TGKN (2646 rows)\n",
      "Saved: TRMK (3948 rows)\n",
      "Saved: UGLD (356 rows)\n",
      "Saved: VSMO (2716 rows)\n",
      "Saved: RDRB (1326 rows)\n",
      "Saved: VEON-RX (830 rows)\n",
      "Saved: AVAN (1767 rows)\n",
      "Saved: KZOS (2658 rows)\n",
      "Saved: KZOSP (2612 rows)\n",
      "Saved: LNZL (2712 rows)\n",
      "Saved: LNZLP (2714 rows)\n",
      "Saved: BLNG (2621 rows)\n",
      "Saved: DZRD (2289 rows)\n",
      "Saved: DZRDP (2526 rows)\n",
      "Saved: MGNZ (1840 rows)\n",
      "Saved: BSPBP (986 rows)\n",
      "Saved: NKNC (2704 rows)\n",
      "Saved: NKNCP (2716 rows)\n",
      "Saved: GEMA (1415 rows)\n",
      "Saved: KLVZ (285 rows)\n",
      "Saved: APRI (176 rows)\n",
      "Saved: ABRD (2411 rows)\n",
      "Saved: UTAR (3219 rows)\n",
      "Saved: BANE (2719 rows)\n",
      "Saved: BANEP (2719 rows)\n",
      "Saved: ASSB (2448 rows)\n",
      "Saved: AMEZ (2689 rows)\n",
      "Saved: USBN (2682 rows)\n",
      "Saved: BISVP (2376 rows)\n",
      "Saved: BRZL (2523 rows)\n",
      "Saved: VLHZ (2603 rows)\n",
      "Saved: VGSB (2301 rows)\n",
      "Saved: VGSBP (2244 rows)\n",
      "Saved: VSYD (2013 rows)\n",
      "Saved: VSYDP (1797 rows)\n",
      "Saved: GAZA (2400 rows)\n",
      "Saved: GAZAP (2058 rows)\n",
      "Saved: GAZT (4 rows)\n",
      "Saved: GAZS (3 rows)\n",
      "Saved: GAZC (5 rows)\n",
      "Saved: GTRK (1716 rows)\n",
      "Saved: RTGZ (2074 rows)\n",
      "Saved: SIBN (2831 rows)\n",
      "Saved: GCHE (3276 rows)\n",
      "Saved: RBCM (2621 rows)\n",
      "Saved: DVEC (2681 rows)\n",
      "Saved: EELT (1326 rows)\n",
      "Saved: ZVEZ (2355 rows)\n",
      "Saved: ZILL (2569 rows)\n",
      "Saved: RUSI (1732 rows)\n",
      "Saved: INGR (1254 rows)\n",
      "Saved: IGST (2342 rows)\n",
      "Saved: IGSTP (2120 rows)\n",
      "Saved: KLSB (2258 rows)\n",
      "Saved: KOGK (2081 rows)\n",
      "Saved: KRSB (2398 rows)\n",
      "Saved: KRSBP (2433 rows)\n",
      "Saved: KAZT (2303 rows)\n",
      "Saved: KAZTP (2137 rows)\n",
      "Saved: KGKC (1482 rows)\n",
      "Saved: KGKCP (1494 rows)\n",
      "Saved: LMBZ (110 rows)\n",
      "Saved: LVHK (2446 rows)\n",
      "Saved: LPSB (1393 rows)\n",
      "Saved: MGKL (326 rows)\n",
      "Saved: MSTT (2699 rows)\n",
      "Saved: MGNT (3583 rows)\n",
      "Saved: MRSB (2488 rows)\n",
      "Saved: MGTS (2716 rows)\n",
      "Saved: MGTSP (3027 rows)\n",
      "Saved: KROT (2546 rows)\n",
      "Saved: KROTP (2492 rows)\n",
      "Saved: NFAZ (2313 rows)\n",
      "Saved: VJGZ (1945 rows)\n",
      "Saved: VJGZP (2044 rows)\n",
      "Saved: NSVZ (2217 rows)\n",
      "Saved: UWGN (1748 rows)\n",
      "Saved: NKSH (2389 rows)\n",
      "Saved: NKHP (2324 rows)\n",
      "Saved: NMTP (2719 rows)\n",
      "Saved: UNAC (2716 rows)\n",
      "Saved: PAZA (1640 rows)\n",
      "Saved: PMSB (2483 rows)\n",
      "Saved: PMSBP (2666 rows)\n",
      "Saved: CHGZ (1726 rows)\n",
      "Saved: ROST (2741 rows)\n",
      "Saved: RKKE (2512 rows)\n",
      "Saved: LSNG (2674 rows)\n",
      "Saved: LSNGP (2673 rows)\n",
      "Saved: MRKK (2715 rows)\n",
      "Saved: TORS (2037 rows)\n",
      "Saved: TORSP (2538 rows)\n",
      "Saved: MRKY (2714 rows)\n",
      "Saved: ROLO (2496 rows)\n",
      "Saved: RZSB (2326 rows)\n",
      "Saved: SPBE (844 rows)\n",
      "Saved: KRKN (1962 rows)\n",
      "Saved: KRKNP (2540 rows)\n",
      "Saved: SARE (2585 rows)\n",
      "Saved: SAREP (2553 rows)\n",
      "Saved: SVET (853 rows)\n",
      "Saved: SVETP (221 rows)\n",
      "Saved: MFGS (2377 rows)\n",
      "Saved: MFGSP (2561 rows)\n",
      "Saved: JNOS (2238 rows)\n",
      "Saved: JNOSP (2367 rows)\n",
      "Saved: CARM (454 rows)\n",
      "Saved: STSB (2629 rows)\n",
      "Saved: STSBP (2675 rows)\n",
      "Saved: VRSB (1889 rows)\n",
      "Saved: VRSBP (1856 rows)\n",
      "Saved: KBSB (2175 rows)\n",
      "Saved: MISB (1752 rows)\n",
      "Saved: MISBP (1739 rows)\n",
      "Saved: NNSB (1884 rows)\n",
      "Saved: NNSBP (2226 rows)\n",
      "Saved: RTSB (1924 rows)\n",
      "Saved: RTSBP (2221 rows)\n",
      "Saved: YRSB (1548 rows)\n",
      "Saved: YRSBP (1703 rows)\n",
      "Saved: KRKOP (2337 rows)\n",
      "Saved: TASB (2149 rows)\n",
      "Saved: TASBP (2266 rows)\n",
      "Saved: TTLK (2649 rows)\n",
      "Saved: TGKB (2716 rows)\n",
      "Saved: TGKBP (2536 rows)\n",
      "Saved: TUZA (2167 rows)\n",
      "Saved: UKUZ (2589 rows)\n",
      "Saved: URKZ (2322 rows)\n",
      "Saved: LIFE (2382 rows)\n",
      "Saved: HIMCP (2383 rows)\n",
      "Saved: GECO (496 rows)\n",
      "Saved: WTCM (2470 rows)\n",
      "Saved: WTCMP (2080 rows)\n",
      "Saved: CNTL (2527 rows)\n",
      "Saved: CNTLP (2613 rows)\n",
      "Saved: PRFN (1530 rows)\n",
      "Saved: CHKZ (1931 rows)\n",
      "Saved: CHMK (2715 rows)\n",
      "Saved: ELMT (220 rows)\n",
      "Saved: UNKL (2427 rows)\n",
      "Saved: IRKT (2718 rows)\n",
      "Saved: YAKG (2194 rows)\n",
      "Saved: YKEN (2815 rows)\n",
      "Saved: YKENP (2453 rows)\n",
      "Saved: KUZB (2469 rows)\n",
      "Saved: TNSE (2367 rows)\n",
      "Saved: DIOD (2691 rows)\n",
      "Saved: ZAYM (254 rows)\n",
      "Saved: NAUK (2338 rows)\n",
      "Saved: OMZZP (2334 rows)\n",
      "Saved: RGSS (2443 rows)\n",
      "Saved: KCHE (2294 rows)\n",
      "Saved: KCHEP (1905 rows)\n",
      "Saved: MAGE (2346 rows)\n",
      "Saved: MAGEP (2341 rows)\n",
      "Saved: SAGO (2891 rows)\n",
      "Saved: SAGOP (2917 rows)\n",
      "Saved: SLEN (2039 rows)\n",
      "Saved: PRMB (1526 rows)\n",
      "Saved: KMEZ (2576 rows)\n",
      "Saved: ARSA (2533 rows)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "from time import sleep\n",
    "\n",
    "DB_NAME = \"moex_candles.db\"\n",
    "DATA_DIR = \"csv_data\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# --- Создание таблиц SQLite ---\n",
    "def create_tables():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS securities (\n",
    "            ticker TEXT PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            boardid TEXT,\n",
    "            type TEXT,\n",
    "            currency TEXT,\n",
    "            is_active INTEGER DEFAULT 1\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS candles (\n",
    "            ticker TEXT,\n",
    "            tradedate TEXT,\n",
    "            open REAL,\n",
    "            high REAL,\n",
    "            low REAL,\n",
    "            close REAL,\n",
    "            volume REAL,\n",
    "            value REAL,\n",
    "            boardid TEXT,\n",
    "            PRIMARY KEY (ticker, tradedate)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# --- Получение исторических данных с MOEX ---\n",
    "def fetch_candles(ticker, board='TQBR'):\n",
    "    url = f\"https://iss.moex.com/iss/engines/stock/markets/shares/boards/{board}/securities/{ticker}/candles.json\"\n",
    "    params = {\n",
    "        \"from\": \"2000-01-01\",\n",
    "        \"interval\": 24,\n",
    "        \"iss.meta\": \"off\",\n",
    "        \"iss.json\": \"extended\",\n",
    "        \"candles.columns\": \"begin,open,high,low,close,value,volume\"\n",
    "    }\n",
    "\n",
    "    all_data = []\n",
    "    start = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(url, params={**params, \"start\": start}, timeout=15)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "\n",
    "            if len(data) < 2 or \"candles\" not in data[1]:\n",
    "                break\n",
    "\n",
    "            candles = data[1][\"candles\"]\n",
    "            if not candles:\n",
    "                break\n",
    "\n",
    "            all_data.extend(candles)\n",
    "\n",
    "            start += 500\n",
    "            sleep(0.2)  # чтобы не получить бан\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(all_data, columns=[\"begin\", \"open\", \"high\", \"low\", \"close\", \"value\", \"volume\"])\n",
    "    df.rename(columns={\"begin\": \"tradedate\"}, inplace=True)\n",
    "    df[\"tradedate\"] = pd.to_datetime(df[\"tradedate\"]).dt.date  # удаляем время\n",
    "    df.insert(0, \"ticker\", ticker)\n",
    "    df[\"boardid\"] = board\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Сохранение в CSV и SQLite ---\n",
    "def save_data(df):\n",
    "    ticker = df[\"ticker\"].iloc[0]\n",
    "\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=[\"ticker\", \"tradedate\"])\n",
    "    after = len(df)\n",
    "    removed = before - after\n",
    "    if removed > 0:\n",
    "        print(f\"Removed {removed} duplicate rows for {ticker}\")\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(os.path.join(DATA_DIR, f\"{ticker}.csv\"), index=False)\n",
    "\n",
    "    # Save to SQLite\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    try:\n",
    "        df.to_sql(\"candles\", conn, if_exists=\"append\", index=False)\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        print(f\"❌ Ошибка вставки {ticker}: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# --- Пример работы ---\n",
    "if __name__ == \"__main__\":\n",
    "    create_tables()\n",
    "    tickers = tickers_list  # заменишь на свой список\n",
    "\n",
    "    for ticker in tickers:\n",
    "        df = fetch_candles(ticker)\n",
    "        if not df.empty:\n",
    "            save_data(df)\n",
    "            print(f\"Saved: {ticker} ({len(df)} rows)\")\n",
    "        else:\n",
    "            print(f\"No data for {ticker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ETLN (1290 rows)\n",
      "Saved: FIXP (1016 rows)\n",
      "Saved: QIWI (2710 rows)\n",
      "Saved: OKEY (1073 rows)\n",
      "Saved: OZON (1088 rows)\n",
      "Saved: AGRO (2475 rows)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlite3\n",
    "from time import sleep\n",
    "\n",
    "DB_NAME = \"moex_candles.db\"\n",
    "DATA_DIR = \"csv_data\"\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# --- Создание таблиц SQLite ---\n",
    "def create_tables():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS securities (\n",
    "            ticker TEXT PRIMARY KEY,\n",
    "            name TEXT,\n",
    "            boardid TEXT,\n",
    "            type TEXT,\n",
    "            currency TEXT,\n",
    "            is_active INTEGER DEFAULT 1\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS candles (\n",
    "            ticker TEXT,\n",
    "            tradedate TEXT,\n",
    "            open REAL,\n",
    "            high REAL,\n",
    "            low REAL,\n",
    "            close REAL,\n",
    "            volume REAL,\n",
    "            value REAL,\n",
    "            boardid TEXT,\n",
    "            PRIMARY KEY (ticker, tradedate)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# --- Получение исторических данных с MOEX ---\n",
    "def fetch_candles(ticker, board='TQBR'):\n",
    "    url = f\"https://iss.moex.com/iss/engines/stock/markets/shares/boards/{board}/securities/{ticker}/candles.json\"\n",
    "    params = {\n",
    "        \"from\": \"2000-01-01\",\n",
    "        \"interval\": 24,\n",
    "        \"iss.meta\": \"off\",\n",
    "        \"iss.json\": \"extended\",\n",
    "        \"candles.columns\": \"begin,open,high,low,close,value,volume\"\n",
    "    }\n",
    "\n",
    "    all_data = []\n",
    "    start = 0\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(url, params={**params, \"start\": start}, timeout=15)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "\n",
    "            if len(data) < 2 or \"candles\" not in data[1]:\n",
    "                break\n",
    "\n",
    "            candles = data[1][\"candles\"]\n",
    "            if not candles:\n",
    "                break\n",
    "\n",
    "            all_data.extend(candles)\n",
    "\n",
    "            start += 500\n",
    "            sleep(0.2)  # чтобы не получить бан\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(all_data, columns=[\"begin\", \"open\", \"high\", \"low\", \"close\", \"value\", \"volume\"])\n",
    "    df.rename(columns={\"begin\": \"tradedate\"}, inplace=True)\n",
    "    df[\"tradedate\"] = pd.to_datetime(df[\"tradedate\"]).dt.date  # удаляем время\n",
    "    df.insert(0, \"ticker\", ticker)\n",
    "    df[\"boardid\"] = board\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Сохранение в CSV и SQLite ---\n",
    "def save_data(df):\n",
    "    ticker = df[\"ticker\"].iloc[0]\n",
    "\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=[\"ticker\", \"tradedate\"])\n",
    "    after = len(df)\n",
    "    removed = before - after\n",
    "    if removed > 0:\n",
    "        print(f\"Removed {removed} duplicate rows for {ticker}\")\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(os.path.join(DATA_DIR, f\"{ticker}.csv\"), index=False)\n",
    "\n",
    "    # Save to SQLite\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    try:\n",
    "        df.to_sql(\"candles\", conn, if_exists=\"append\", index=False)\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        print(f\"❌ Ошибка вставки {ticker}: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# --- Пример работы ---\n",
    "if __name__ == \"__main__\":\n",
    "    create_tables()\n",
    "    tickers = tickers_list  # заменишь на свой список\n",
    "\n",
    "    for ticker in tickers:\n",
    "        df = fetch_candles(ticker)\n",
    "        if not df.empty:\n",
    "            save_data(df)\n",
    "            print(f\"Saved: {ticker} ({len(df)} rows)\")\n",
    "        else:\n",
    "            print(f\"No data for {ticker}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Migrated FIVE → X5: 1540 rows\n",
      "Migrated MAIL → VKCO: 371 rows\n",
      "Migrated CIAN → CNRU: 803 rows\n",
      "Migrated HHRU → HEAD: 962 rows\n"
     ]
    }
   ],
   "source": [
    "# --- Сохранение в CSV и SQLite ---\n",
    "def save_data(df):\n",
    "    ticker = df[\"ticker\"].iloc[0]\n",
    "\n",
    "    before = len(df)\n",
    "    df = df.drop_duplicates(subset=[\"ticker\", \"tradedate\"])\n",
    "    after = len(df)\n",
    "    removed = before - after\n",
    "    if removed > 0:\n",
    "        print(f\"Removed {removed} duplicate rows for {ticker}\")\n",
    "\n",
    "    # Преобразуем tradedate в строку, чтобы избежать ошибок в SQLite\n",
    "    df[\"tradedate\"] = pd.to_datetime(df[\"tradedate\"]).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Append to CSV (if exists)\n",
    "    csv_path = os.path.join(DATA_DIR, f\"{ticker}.csv\")\n",
    "    if os.path.exists(csv_path):\n",
    "        old_df = pd.read_csv(csv_path, parse_dates=[\"tradedate\"])\n",
    "        df = pd.concat([old_df, df], ignore_index=True)\n",
    "        df.drop_duplicates(subset=[\"ticker\", \"tradedate\"], inplace=True)\n",
    "\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Преобразуем все данные в строковый формат, чтобы избежать ошибок с типами данных\n",
    "    df = df.applymap(str)\n",
    "\n",
    "    # Save to SQLite\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    try:\n",
    "        df.to_sql(\"candles\", conn, if_exists=\"append\", index=False)\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        print(f\"❌ Ошибка вставки {ticker}: {e}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "\n",
    "# --- Сбор данных по старому тикеру и сохранение под новым ---\n",
    "def migrate_ticker(old_ticker, new_ticker):\n",
    "    df = fetch_candles(old_ticker)\n",
    "    if df.empty:\n",
    "        print(f\"No data for {old_ticker}\")\n",
    "        return\n",
    "    df[\"ticker\"] = new_ticker  # переименовываем тикер\n",
    "    save_data(df)\n",
    "    print(f\"Migrated {old_ticker} → {new_ticker}: {len(df)} rows\")\n",
    "\n",
    "# --- Пример работы ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "   \n",
    "    # Миграция старых тикеров\n",
    "    migration_map = {\n",
    "        \"FIVE\": \"X5\",\n",
    "        \"MAIL\": \"VKCO\",\n",
    "        \"CIAN\": \"CNRU\",\n",
    "        \"HHRU\": \"HEAD\"\n",
    "    }\n",
    "\n",
    "    for old, new in migration_map.items():\n",
    "        migrate_ticker(old, new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
